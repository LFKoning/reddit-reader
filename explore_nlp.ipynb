{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reddit_reader.database import Database\n",
    "\n",
    "from helpers import detect_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database(\"reddit_data/reddit.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame(db.query(\"SELECT * FROM submissions\"))\n",
    "submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "submissions = submissions.assign(\n",
    "    num_comments=submissions[\"num_comments\"].astype(int),\n",
    "    ups=submissions[\"ups\"].astype(int),\n",
    "    downs=submissions[\"downs\"].astype(int),\n",
    "    score=submissions[\"score\"].astype(int),\n",
    "    language=submissions[\"selftext\"].map(detect_language),\n",
    "    created_dt=pd.to_datetime(submissions[\"created\"].astype(float), unit=\"s\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detected languages\n",
    "(\n",
    "    submissions[\"language\"]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(figsize=(6, 3), title=\"Detected Language\")\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions[submissions[\"language\"] == \"EN\"].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts per day\n",
    "(\n",
    "    submissions\n",
    "    .assign(post_date=submissions[\"created_dt\"].dt.date)\n",
    "    .groupby(\"post_date\", as_index=False)\n",
    "    .agg(post_count=(\"id\", \"nunique\"))\n",
    "    .plot.scatter(\n",
    "        x=\"post_date\",\n",
    "        y=\"post_count\",\n",
    "        title=\"Posts per Day\",\n",
    "        figsize=(18, 3),\n",
    "        alpha=0.5,\n",
    "        ylim=(0, 8)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"num_comments\", \"ups\", \"score\", \"downs\"\n",
    "\n",
    "fig, axes = plt.subplots(1, len(columns), figsize=(len(columns) * 4, 3))\n",
    "for idx, column in enumerate(columns):\n",
    "    (\n",
    "        submissions[column]\n",
    "        .plot.hist(\n",
    "            bins=50,\n",
    "            edgecolor=\"white\",\n",
    "            ax=axes[idx],\n",
    "        )\n",
    "    )\n",
    "    axes[idx].axvline(submissions[column].median(), color=\"red\")\n",
    "    axes[idx].set_title(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    submissions[\"link_flair_text\"]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(\n",
    "        figsize=(10, 4),\n",
    "        title=\"Submission Category\"\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author \"None\" means user account was deleted.\n",
    "(\n",
    "    submissions[\"author\"]\n",
    "    .value_counts()\n",
    "    .head(15)\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(\n",
    "        figsize=(10, 4),\n",
    "        title=\"Authors\"\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dutch language model.\n",
    "nlp = spacy.load(\"nl_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize docs.\n",
    "docs = pd.Series(nlp.pipe(submissions[\"selftext\"], n_process=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entities with ORG label.\n",
    "organizations = (\n",
    "    docs\n",
    "    .map(\n",
    "        lambda doc: [\n",
    "            ent.text.lower().strip(\"'s\") for ent in doc.ents\n",
    "            if ent.label_ == \"ORG\"\n",
    "        ]\n",
    "    )\n",
    "    # One organization per row\n",
    "    .explode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    organizations\n",
    "    .value_counts()\n",
    "    .head(20)\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(\n",
    "        title=\"Common Organizations\",\n",
    "        figsize=(8, 5),\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entities with PERSON label.\n",
    "persons = (\n",
    "    docs\n",
    "    .map(\n",
    "        lambda doc: [\n",
    "            ent.text.lower().strip(\"'s\") for ent in doc.ents\n",
    "            if ent.label_ == \"PERSON\"\n",
    "        ]\n",
    "    )\n",
    "    # One person per row\n",
    "    .explode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    persons\n",
    "    .value_counts()\n",
    "    .head(20)\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(\n",
    "        title=\"Common Persons\",\n",
    "        figsize=(8, 5),\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.DataFrame(db.query(\"SELECT * FROM comments\"))\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "comments = comments.assign(\n",
    "    ups=comments[\"ups\"].astype(int),\n",
    "    downs=comments[\"downs\"].astype(int),\n",
    "    language=submissions[\"selftext\"].map(detect_language),\n",
    "    created_dt=pd.to_datetime(submissions[\"created\"].astype(float), unit=\"s\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author \"None\" means user account was deleted.\n",
    "(\n",
    "    comments[\"author\"]\n",
    "    .value_counts()\n",
    "    .head(15)\n",
    "    .sort_values(ascending=True)\n",
    "    .plot.barh(figsize=(10, 4), title=\"Authors\")\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted versus valid comments.\n",
    "(\n",
    "    comments[\"body\"]\n",
    "    .map(lambda v: \"deleted\" if v in (\"[deleted]\", \"[removed]\") else \"valid\")\n",
    "    .value_counts()\n",
    "    .plot.barh(figsize=(6, 3), title=\"Deleted Comments\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up and down votes\n",
    "columns = \"ups\", \"downs\"\n",
    "\n",
    "fig, axes = plt.subplots(1, len(columns), figsize=(len(columns) * 4, 3))\n",
    "for idx, column in enumerate(columns):\n",
    "    (\n",
    "        comments[column]\n",
    "        .plot.hist(\n",
    "            bins=50,\n",
    "            edgecolor=\"white\",\n",
    "            ax=axes[idx],\n",
    "        )\n",
    "    )\n",
    "    axes[idx].axvline(comments[column].median(), color=\"red\")\n",
    "    axes[idx].set_title(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment length\n",
    "post_length = comments[\"body\"].map(lambda t: len(t.split()))\n",
    "post_length = post_length.clip(upper=post_length.quantile(.98))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "(\n",
    "    post_length\n",
    "    .plot.hist(\n",
    "        bins=100,\n",
    "        edgecolor=\"white\",\n",
    "        ax=ax\n",
    "    )\n",
    ")\n",
    "ax.axvline(post_length.median(), color=\"red\")\n",
    "ax.set_title(\"Comment Word Count\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_text(text):\n",
    "    \"\"\"Cleanse submission body text.\"\"\"\n",
    "    # Strip encoded characters\n",
    "    text = re.sub(r\"&#x[0-9]+B;\", \"\", text)\n",
    "\n",
    "    # Strip URLs\n",
    "    text = re.sub(r\"https?://[^\\s]+\", \"\", text)\n",
    "\n",
    "    # Strip excess whitespace\n",
    "    text = re.sub(r\"[\\s\\n\\r]+\", \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \"de\", \"een\", \"en\", \"of\", \"het\", \"van\", \"is\", \"te\", \"met\",\n",
    "    \"wat\", \"dat\", \"dit\", \"om\", \"op\", \"in\", \"voor\", \"er\", \"naar\",\n",
    "    \"ik\", \"jij\", \"je\", \"jullie\", \"zij\", \"hij\", \"haar\", \"mijn\", \"hun\", \"hen\",\n",
    "    \"hallo\", \"hi\", \"groet\", \"groeten\", \"groetjes\", \"welkom\",\n",
    "    \"dank\", \"bedankt\", \"alvast\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer =  ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "topic_model = BERTopic(\n",
    "    language=\"Dutch\",\n",
    "    nr_topics=50,\n",
    "    vectorizer_model=vectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = (\n",
    "    submissions.query(\"selftext != '' & language == 'NL'\")\n",
    "    [\"selftext\"]\n",
    "    .map(cleanse_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = texts.map(lambda s: s.split(\".\")).explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent[sent != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
